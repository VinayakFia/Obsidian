> [!warning] TODO
> - [ ] COMP4920 - Assignment 1
> - [ ] ðŸ“… 2024-10-03 Proof Read
> - [ ] ðŸ“… 2024-10-03 Fix references
> - [ ] ðŸ“… 2024-10-02 Finish Draft
> - [ ] ðŸ“… 2024-10-02 Edit

> [!info] Expound and assess rule-based/Kantian ethics. Analyse the extent to which such an ethics might be used to design an automated ethics as per the readings in section 1.2 below. What do you think that the risks and opportunities of such an automated ethics might be? Why? Justify your answer with explicit, detailed, expositional reference to at least one of the suggested readings in section 1.2 below.

*Coeckelbergh, M. (2021): How to Use Virtue Ethics for Thinking About the Moral Standing of Social Robots: A Relational Interpretation in Terms of Practices, Habits, and Performance, International Journal of Social Robotics, 13:31â€“40.*

*Sparrow, S. (2021): Virtue and Vice in Our Relationships with Robots: Is There an Asymmetry and How Might it be Explained? International Journal of Social Robotics (2021) 13:23â€“29.*

*Coeckelbergh, M. (2021): Does kindness towards robots lead to virtue? A reply to Sparrowâ€™s asymmetry argument, Ethics and Information Technology (2021) 23:649â€“656.*

*Coeckelbergh, M. (2021): Should We Treat Teddy Bear 2.0 as a Kantian Dog? Four Arguments for the Indirect Moral Standing of Personal Social Robots, with Implications for Thinking About Animals and Humans, Minds and Machines (2021) 31:337â€“360.*

## Draft 1
Kantian ethics is a deontological ethical framework based upon the categorical imperative. Kantian ethics is effective for the modern individual to apply in daily life, and serves as an effective tool for organisations to make decisions. The extent to which ethics can be automated refers to the amount of the ethical decision making process that may be handled by a machine. Kantian ethics cannot be automated to the extent of requiring no human interaction, which I will refer to as complete automation, as it fundamentally violates the categorical imperative. Complete automation provides great opportunity for efficiency gains, however, such applications pose incredible risk to those affected. Kantian ethics can be automated to the extent of a proof assistant. Such automation provides the opportunity to alleviate the burden of proving maxims with no risk. Finally, I will argue that, although impure to Kant, a system combining formal maxim proof with other technologies may

Kantian ethics is based on the categorical imperative, which, in its first formulation states that one must act only according to maxims that they wish to become universal law (Kant 2008 p11). Each act represents one or more maxims, and one must formulate such maxims by deleting references to supplementary details such as places, times, or persons (O'Neill 1985 p161). Then, one must reason whether said maxims ought to be universal law, that is, it ought to be moral and acted upon by all. Suppose a moral agent was considering lying to their friend about attending their birthday, they may reduce this act to 'I ought to lie'. Then, rationalising that certainly they would not wish a world where lying be moral, they would conclude that lying to their friend is immoral.

Kant, in his second formulation, states that we must never treat humans as a mere means, but always at the same time an end (Kant 2008 p29). As O'Neil expounds, to use someone as a mere means is to involve them in a scheme of action to which they could not in principle consent (Oâ€™Neill, 1986). The earlier proposed scheme of lying could indeed not be consented to by the deceived party, as the consenting party is unaware of the real maxim.

Kantian ethics provides a effective framework for the modern individual to rationalise actions, although requires great, and perhaps impractical, nuance to reason certain situations. Unlike utilitarianism's infinite computation of the hedonic calculus, one may reasonably form maxims, and reason the universality of each in a sensible amount of time. Similarly, one may consider the human dignity, autonomy, and respect of involved parties. Critics argue that there exist certain situations, such as the axe murderer problem referenced in Kant's essay 'On the Supposed Right to Lie', where a moral agent must take moral action that results in grave negative consequences. However, modern Kantian ethicists argue that doing so would violate one's self-respect, as one becomes a 'tool for evil' (Korsgaard 1986 p340). Such situations require such great nuance and would be difficult and impractical to reason.

Kantian ethics enables organisations and governments to make pragmatic decisions that respect all involved parties. Kantian ethics requires that one respect each individual as a rational person with their own maxims (O'Neill 1983 p162). Through Kantian ethics, organisations can ensure that rules, decisions, and actions taken may at least be 'in principal consent(ed) to' by all involved parties. For example, Kantian ethics views abortion to have moral considerations against it, but is sometimes permissible, and sometimes even required (Denis 2008 p117). As such, a society with laws based upon Kantian ethics would see abortion's ban as impermissible as it cannot be universalised, but equally respect those who based upon their own ends did see it as such.

To the extent of a proof assistance, Kantian ethics may effectively be implemented, and moreover be used to aid in formally reasoning the morality of maxims. As demonstrated by Lavanya Singh, who builds upon prior research in the field of ethical automation; Kantian ethics can be formalised into the rigorous semantics of proof languages such as Isabelle. However, the automation lies within the proving of maxims, not their conception. The critical step of forming the 'maxim' of an action seems quite indeterminable (Kitcher 2003) as it is "the subjective principles of willing" (L. Singh p4). Ultimately, the burden falls upon the human moral agent conceive of sophisticated assumptions, maxims, and specifications. Such automation serves as a valuable  opportunity for large organisations to ethically rectify complex moral decisions, such as those in relation to regulation and law making. There is no risk in using proof systems, as they rather than making decisions for human moral agents, they assist human moral agents to quickly and more rigorously ethically reason decisions.

Complete automation of Kantian ethics, regardless of implementation, is incompatible with Kant's formulations of the categorical imperative. Kant's formula of humanity (FH) - specifically to treat individuals as ends in themselves never as a mere means - requires that the persons capable of moral evaluation must be considered as ends in themselves (Nath, R., and Sahu, V. 2021). This gives rise to the question: can we consider artificial moral agents as ends in themselves? As argued by Weizenbaum, 'computer intelligence is alien to genuine human problems and concerns'. Indeed, there are several functions artificial intelligence is unable to replicate including intuition, discretion, and instinct. The inability for artificial intelligence to acquire such features lead them to be incapable of moral action. Moreover, any implementation of a Kantian artificial moral agent follows procedures that ultimately reduce it to a hypothetical moral agent. (Manna, Nath 2021: 144), and as such only be amoral. However, we must acknowledge that as AI becomes more powerful, prevalent, and independent, it must be equipped with ethical reasoning (L. Singh p12). Complete automation of Kantian ethics is not possible, however, an impure artificial agent capable of generating maxims in conjunction with formal maxim proof software as created by Singh would be a step towards AI regulation and safety.

Kantian ethics is an effective foundation for rationalising decisions. However, its distinct lack of human qualities required of a moral agent make it unsuitable for complete automation. Kantian proof systems in contrast serve as effective tools for humans to formalise the morality of maxims.

## References
https://www.qil-qdi.org/kantian-ethics-age-artificial-intelligence-robotics/
https://www.amazon.com.au/Computer-Power-Human-Reason-Calculation/dp/0716704633
https://www.earlymoderntexts.com/assets/pdfs/kant1785.pdf
https://usna.edu/CoreEthics/Essays/ONeil_Formula_of_Ends.pdf
http://www.sophia-project.org/uploads/1/3/9/5/13955288/kant_lying.pdf
https://webcms3.cse.unsw.edu.au/static/uploads/course/COMP4920/24T3/b09949bce1345dd8998cca71826a2f0b5d1014e9242357c1d9cadc8ecc8f3b82/WEEK_1_LECTURE_2_READINGS_4920_24T1.pdf
https://www-jstor-org.wwwproxy1.library.unsw.edu.au/stable/2265252?seq=4
https://www-jstor-org.wwwproxy1.library.unsw.edu.au/stable/40041154?searchText=%28kantian+ethics+maxim%29+AND+%28Kant+abortion%29&seq=1
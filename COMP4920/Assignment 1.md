Kantian ethics is a deontological ethical framework that provides a sound framework for individuals and organisations to reason the morality of their decisions. The extent to which ethics can be automated refers to the amount of the ethical decision making process that may be handled by a machine. Kantian ethics can be automated to the extent of a proof assistant with no risk. However, Kantian ethics cannot be automated to the extent of requiring no human interaction, which I will refer to as complete automation, as it fundamentally violates the categorical imperative. Finally I discuss the opportunity and risks of employing automated Kantian ethics in modern software systems.

Kantian ethics is based on the categorical imperative, which, in its first formulation states that one must act only according to maxims that they wish to become universal law (Kant 2008 p11). Each act represents one or more maxims, and one may formulate such maxims by deleting references to supplementary details such as places, times, or persons (O'Neill 1985 p161). Then, one must reason whether said maxims ought to be universal law, that is, it ought to be moral and acted upon by all. Suppose a moral agent was considering lying to their friend about attending their birthday, they may reduce this act to 'I ought to lie'. Then, rationalising that certainly they would not wish a world where lying be moral, they would conclude that lying to their friend is immoral.

Kant, in his second formulation, states that we must never treat humans as a mere means, but always at the same time an end (Kant 2008 p29). As O'Neil expounds, to use someone as a mere means is to involve them in a scheme of action to which they could not in principle consent (O’Neill, 1986). The earlier proposed scheme of lying could indeed not be consented to by the deceived party, as the deceived party is unaware of the real maxim.

Kantian ethics provides a effective framework for the modern individual to rationalise actions. Although, it may requires great, and perhaps impractical nuance to reason certain situations. Unlike utilitarianism's infinite computation of the hedonic calculus, one may reasonably form maxims, and reason the universality of each in a sensible amount of time. Similarly, one may consider the human dignity, autonomy, and respect of involved parties. Critics argue that there exist certain situations, such as the axe murderer problem referenced in Kant's essay 'On the Supposed Right to Lie', where a moral agent must take moral action that results in grave negative consequences. However, modern Kantian ethicists argue that doing so would violate one's self-respect, as one becomes a 'tool for evil' (Korsgaard 1986 p340). Such situations require such great nuance and would be difficult and impractical to reason.

Kantian ethics enables organisations and governments to make pragmatic decisions that respect all involved parties. Kantian ethics requires that one respect each individual as a rational person with their own maxims (O'Neill 1983 p162). Through Kantian ethics, organisations can ensure that rules, decisions, and actions taken may at least be 'in principal consent(ed) to' by all involved parties. For example, Kantian ethics views that abortion may be immoral, but sometimes permissible, and sometimes even required (Denis 2008 p117). As such, a society with laws based upon Kantian ethics would see abortion's ban as impermissible as it cannot be universalised. It would equally respect those, who based upon their own ends, did see it immoral.

To the extent of a proof assistance, Kantian ethics may effectively be implemented, and moreover be used to aid in formally reasoning the morality of maxims. As demonstrated by Lavanya Singh, who builds upon prior research in the field of ethical automation; Kantian ethics can be formalised into the rigorous semantics of proof languages such as Isabelle. However, the automation lies within the proving of maxims, not their conception. The critical step of forming the 'maxim' of an action seems quite indeterminable (Kitcher 2003), and indeed is not implemented by Singh. Ultimately, the burden falls upon the human moral agent to conceive of sophisticated assumptions, maxims, and specifications. Such automation serves as a valuable  opportunity for large organisations to ethically rectify complex moral decisions, such as those in relation to regulation and law making. There is no risk in using proof systems, as rather than making decisions for human moral agents, they assist us to quickly rigorously reason the ethicality of decisions.

Complete automation of Kantian ethics, regardless of implementation, is incompatible with Kant's formulations of the categorical imperative. Kant's formula of humanity (FH) - specifically to treat individuals as ends in themselves never as a mere means - requires that the persons capable of moral evaluation must be considered as ends in themselves (Nath, R., and Sahu, V. 2021). This gives rise to the question: can we consider artificial moral agents as ends in themselves? As argued by Weizenbaum, 'computer intelligence is alien to genuine human problems and concerns'. Indeed, there are several functions artificial intelligence is unable to replicate including intuition, discretion, and instinct. The inability for artificial intelligence to acquire such features lead them to be incapable of moral action. Moreover, any implementation of a Kantian artificial moral agent follows procedures that ultimately reduce it to a hypothetical moral agent (Manna, Nath 2021: 144). Maxim proof may be automated, but formation of maxims cannot as they fundamentally require "the subjective principle of willing" (L. Sing p4).

Future implementations of Kantian ethics can address rising safety concerns of critical AI systems. As AI becomes more powerful, prevalent, and independent, it must be equipped with ethical reasoning (L. Singh p12), specifically in regards to critical systems in healthcare, automobiles, and weapons. We have shown that a complete automation of Kantian ethics is not possible. However, lets consider the implications of an impure Kantian agent, specifically an agent that bridges the situation too maxim evaluation with some "moral closeness" heuristic (L.Sing p10). I believe, based upon my evaluation of Kantian ethics on the individual and organisational levels, that such an agent would provide a significant increase to safety to critical systems through. Specifically, it would provide fails safes against execution of immoral actions.

In conclusion, we have assessed that Kantian ethics is a sound framework for individuals and organisations to make decisions. Then, Kantian ethics can be automated to the extent of formal proof software but not completely as it is unable to procure maxims and replicate necessary human features. Finally, we addressed the opportunity of an impure Kantian agent to address rising concerns of AI systems.
## References
Weizenbaum, J 1976, *Computer Power and Human Reason: From Judgement to Calculation* W.H. Freeman And Company, Calafornia.
Kant, I. (1785). _Groundwork for the Metaphysic of Morals_. [online] Available at: https://www.earlymoderntexts.com/assets/pdfs/kant1785.pdf.
O'neill, O. (n.d.). _A Simplified Account of Kant’s Ethics_. [online] Available at: https://usna.edu/CoreEthics/Essays/ONeil_Formula_of_Ends.pdf.
Kant, I. (1797). _On the Supposed Right to Lie From Benevolent Motives_. [online] Available at: http://www.sophia-project.org/uploads/1/3/9/5/13955288/kant_lying.pdf.
Bennet, C. 2015: *What is this thing called ethics*, second
edition, Routledge
Korsgaard, C.M., 1986. The right to lie: Kant on dealing with evil. _Philosophy & Public Affairs_, 15(4), pp.325-349. Available at: http://www.jstor.org/stable/2265252
Denis, L., 2008. Animality and agency: A Kantian approach to abortion. _Philosophy and Phenomenological Research_, 76(1), pp.117-137. Available at: http://www.jstor.org/stable/40041154.
Manna, R. and Nath, R. (2021): *Kantian Moral Agency and the Ethics of Artificial Intelligence*, Problemos vol. 100, pp. 139–151.
Nath, R., and Sahu, V. (2021): *The problem of machine ethics in artificial intelligence, AI &Society*, 35:103–111.
Tonkens, R. (2009): *A Challenge for Machine Ethics, Minds & Machines* (2009) 19:421–438.
Singh, L. (2022): Automated Kantian Ethics: A Faithful Implementation.
Online at https://github.com/lsingh123/automatedkantianethics
Johnson, R. and Cureton, A. (2022). _Kant’s Moral Philosophy_. [online] Stanford Encyclopedia of Philosophy. Available at: https://plato.stanford.edu/entries/kant-moral/

> [!info] Expound and assess rule-based/Kantian ethics. Analyse the extent to which such an ethics might be used to design an automated ethics as per the readings in section 1.2 below. What do you think that the risks and opportunities of such an automated ethics might be? Why? Justify your answer with explicit, detailed, expositional reference to at least one of the suggested readings in section 1.2 below.

Kantian ethics provides a sound framework for the individual to reason the morality of their decisions. To an extent, the proof and rigour of human procured maxims can be supported through formal verification software. However, end to end automation through heuristic tools such as neural networks fundamentally opposes the categorical imperative. Kantian ethics is a deontological ethical framework based upon the categorical imperative. Kantian ethics is effective for the modern individual to apply in daily life, and serves as an effective tool for organisations to make decisions. The extent to which ethics can be automated refers to the amount of the ethical decision making process that may be handled by a machine. Kantian ethics cannot be automated to the extent of requiring no human interaction, which I will refer to as complete automation, as it fundamentally violates the categorical imperative. However, Kantian ethics can be automated to the extent of a proof assistant with no risk. Finally, I will acknowledge that despite its impurity, a system combining formal maxim proof with other technologies is a practical approach to modern ethics.

Kantian ethics is based on the categorical imperative, which, in its first formulation states that one must act only according to maxims that they wish to become universal law (Kant 2008 p11). Each act represents one or more maxims, and one may formulate such maxims by deleting references to supplementary details such as places, times, or persons (O'Neill 1985 p161). Then, one must reason whether said maxims ought to be universal law, that is, it ought to be moral and acted upon by all. Suppose a moral agent was considering lying to their friend about attending their birthday, they may reduce this act to 'I ought to lie'. Then, rationalising that certainly they would not wish a world where lying be moral, they would conclude that lying to their friend is immoral.

Kant, in his second formulation, states that we must never treat humans as a mere means, but always at the same time an end (Kant 2008 p29). As O'Neil expounds, to use someone as a mere means is to involve them in a scheme of action to which they could not in principle consent (O’Neill, 1986). The earlier proposed scheme of lying could indeed not be consented to by the deceived party, as the deceived party is unaware of the real maxim.

Kantian ethics provides a effective framework for the modern individual to rationalise actions. Although, it may requires great, and perhaps impractical nuance to reason certain situations. Unlike utilitarianism's infinite computation of the hedonic calculus, one may reasonably form maxims, and reason the universality of each in a sensible amount of time. Similarly, one may consider the human dignity, autonomy, and respect of involved parties. Critics argue that there exist certain situations, such as the axe murderer problem referenced in Kant's essay 'On the Supposed Right to Lie', where a moral agent must take moral action that results in grave negative consequences. However, modern Kantian ethicists argue that doing so would violate one's self-respect, as one becomes a 'tool for evil' (Korsgaard 1986 p340). Such situations require such great nuance and would be difficult and impractical to reason.

Kantian ethics enables organisations and governments to make pragmatic decisions that respect all involved parties. Kantian ethics requires that one respect each individual as a rational person with their own maxims (O'Neill 1983 p162). Through Kantian ethics, organisations can ensure that rules, decisions, and actions taken may at least be 'in principal consent(ed) to' by all involved parties. For example, Kantian ethics views that abortion may be immoral, but sometimes permissible, and sometimes even required (Denis 2008 p117). As such, a society with laws based upon Kantian ethics would see abortion's ban as impermissible as it cannot be universalised. It would equally respect those, who based upon their own ends, did see it immoral.

To the extent of a proof assistance, Kantian ethics may effectively be implemented, and moreover be used to aid in formally reasoning the morality of maxims. As demonstrated by Lavanya Singh, who builds upon prior research in the field of ethical automation; Kantian ethics can be formalised into the rigorous semantics of proof languages such as Isabelle. However, the automation lies within the proving of maxims, not their conception. The critical step of forming the 'maxim' of an action seems quite indeterminable (Kitcher 2003), and indeed is not implemented by Singh. Ultimately, the burden falls upon the human moral agent to conceive of sophisticated assumptions, maxims, and specifications. Such automation serves as a valuable  opportunity for large organisations to ethically rectify complex moral decisions, such as those in relation to regulation and law making. There is no risk in using proof systems, as rather than making decisions for human moral agents, they assist us to quickly rigorously reason the ethicality of decisions.

Complete automation of Kantian ethics, regardless of implementation, is incompatible with Kant's formulations of the categorical imperative. Kant's formula of humanity (FH) - specifically to treat individuals as ends in themselves never as a mere means - requires that the persons capable of moral evaluation must be considered as ends in themselves (Nath, R., and Sahu, V. 2021). This gives rise to the question: can we consider artificial moral agents as ends in themselves? As argued by Weizenbaum, 'computer intelligence is alien to genuine human problems and concerns'. Indeed, there are several functions artificial intelligence is unable to replicate including intuition, discretion, and instinct. The inability for artificial intelligence to acquire such features lead them to be incapable of moral action. Moreover, any implementation of a Kantian artificial moral agent follows procedures that ultimately reduce it to a hypothetical moral agent (Manna, Nath 2021: 144). Maxim proof may be automated, but formation of maxims cannot as they fundamentally require "the subjective principle of willing" (L. Sing p4).

Finally, we must acknowledge that as AI becomes more powerful, prevalent, and independent, it must be equipped with ethical reasoning (L. Singh p12). Systems such as chatbots and lethal autonomous weapons systems are increasingly used, and lack ethical regulation. The greatest opportunity of automated ethics lies in regulating such systems as they grow increasingly prevalent in our lives. Complete automation of Kantian ethics is impossible, however, an impure artificial agent capable of generating maxims in conjunction with formal maxim proof software as created by Singh would be a step towards regulation and safety of such critical systems.

## References
Weizenbaum, J 1976, *Computer Power and Human Reason: From Judgement to Calculation* W.H. Freeman And Company, Calafornia.
Kant, I. (1785). _Groundwork for the Metaphysic of Morals_. [online] Available at: https://www.earlymoderntexts.com/assets/pdfs/kant1785.pdf.
O'neill, O. (n.d.). _A Simplified Account of Kant’s Ethics_. [online] Available at: https://usna.edu/CoreEthics/Essays/ONeil_Formula_of_Ends.pdf.
Kant, I. (1797). _On the Supposed Right to Lie From Benevolent Motives_. [online] Available at: http://www.sophia-project.org/uploads/1/3/9/5/13955288/kant_lying.pdf.
Bennet, C. 2015: *What is this thing called ethics*, second
edition, Routledge
Korsgaard, C.M., 1986. The right to lie: Kant on dealing with evil. _Philosophy & Public Affairs_, 15(4), pp.325-349. Available at: http://www.jstor.org/stable/2265252
Denis, L., 2008. Animality and agency: A Kantian approach to abortion. _Philosophy and Phenomenological Research_, 76(1), pp.117-137. Available at: http://www.jstor.org/stable/40041154.
Manna, R. and Nath, R. (2021): *Kantian Moral Agency and the Ethics of Artificial Intelligence*, Problemos vol. 100, pp. 139–151.
Nath, R., and Sahu, V. (2021): *The problem of machine ethics in artificial intelligence, AI &Society*, 35:103–111.
Tonkens, R. (2009): *A Challenge for Machine Ethics, Minds & Machines* (2009) 19:421–438.
Singh, L. (2022): Automated Kantian Ethics: A Faithful Implementation.
Online at https://github.com/lsingh123/automatedkantianethics
Johnson, R. and Cureton, A. (2022). _Kant’s Moral Philosophy_. [online] Stanford Encyclopedia of Philosophy. Available at: https://plato.stanford.edu/entries/kant-moral/

- [ ] COMP4920 - Assignment 1

> [!info] Expound and assess rule-based/Kantian ethics. Analyse the extent to which such an ethics might be used to design an automated ethics as per the readings in section 1.2 below. What do you think that the risks and opportunities of such an automated ethics might be? Why? Justify your answer with explicit, detailed, expositional reference to at least one of the suggested readings in section 1.2 below.

*Coeckelbergh, M. (2021): How to Use Virtue Ethics for Thinking About the Moral Standing of Social Robots: A Relational Interpretation in Terms of Practices, Habits, and Performance, International Journal of Social Robotics, 13:31–40.*

*Sparrow, S. (2021): Virtue and Vice in Our Relationships with Robots: Is There an Asymmetry and How Might it be Explained? International Journal of Social Robotics (2021) 13:23–29.*

*Coeckelbergh, M. (2021): Does kindness towards robots lead to virtue? A reply to Sparrow’s asymmetry argument, Ethics and Information Technology (2021) 23:649–656.*

*Coeckelbergh, M. (2021): Should We Treat Teddy Bear 2.0 as a Kantian Dog? Four Arguments for the Indirect Moral Standing of Personal Social Robots, with Implications for Thinking About Animals and Humans, Minds and Machines (2021) 31:337–360.*

## Draft 1
Kantian ethics is based on concept of the *categorical imperative*, which, in its first formulation states that one must act only according to maxims that they wish to become universal law. Each act represents one or more maxims, and one must formulate such maxims by deleting references to supplementary details such as places, times, or persons. Then, one must reason whether said maxims ought to be universal law, that is, it ought to be moral and acted upon by all. Suppose a moral agent was considering lying to their friend about attending their birthday, they may reduce this act to 'I ought to lie'. Then, rationalising that certainly they would not wish a world where lying be moral, they would conclude that lying to their friend is immoral.

Kant, in his second formulation, states that we must never treat humans as a mere means, but always at the same time an end. As O'Neil expounds, to use someone as a mere means is to involve them in a scheme of action to which they could not in principle consent (O’Neill, 1986). The earlier proposed scheme of lying could indeed not be consented to by the deceived party. Moreover, moral laws must respect human rationality, and human autonomy. This second formulation of is based upon the notion of human dignity, which Kant argues is inherent as we are rational beings. 

Kantian ethics provides a practical framework for the modern individual to rationalise actions. Unlike utilitarianism's infinite computation of the hedonic calculus, one may reasonably form maxims, and reason the universality of each. Further Kantian ethics uniquely considers the individual's preference, leading to an ethical framework consistent with the diversity of beliefs in the 21st century. Ultimately deciding whether one chooses a maxim to become universal law is based on their own will. As such, each person, when considering their own actions, is free to choose their morality. Moreover, the actions of others, regardless of one's own beliefs, must also be respected, as one must respect human rationality. This enables a society of varying, even opposing, beliefs that exist in harmony.

I will consider two approaches for the automation of Kantian ethics. Firstly, end-to-end automation through the creation of a Kantian artificial moral agent. Secondly, we will explore automation through formalisation of the Categorial imperative into proof software, which a moral agent utilises to prove the ethicality of a maxim.

Although aspects of Kantian ethics may be automated, a moral agent must ultimately rely upon their own rationality to concretely determine the morality of actions. As demonstrated by Lavanya Singh, who builds upon prior research in the field of ethical automation; Kantian ethics can be formalised into the rigorous semantics of proof languages such as Isabelle. Indeed Singh demonstrates proof of maxims pertaining to ethical dilemmas such as lying, or the morality of joking. However, the critical step of forming the 'maxim' of an action seems quite indeterminable (Kitcher 2003). Singh adopts O'Niell's view that maxims are composed of the act, circumstance, and goal (Singh 2022). Although this serves as a more sophisticated guide for a moral agent to procure maxims, several maxims may still apply to a single action. So, the burden falls upon the user of an ethical proof system to conceive of sophisticated assumptions, maxims, and specifications. To the extent of formally verifying human procured maxims, automation is highly viable, and effective. Such automation serves as a valuable  opportunity for organisations to ethically rectify complex moral decisions, such as those in relation to regulation and law making.

The notion of a Kantian artificial moral agent, regardless of implementation, is incompatible with Kant's formulations of the categorical imperative. Kant's formula of humanity (FH) -specifically to treat individuals as ends in themselves never as a mere means - requires that the persons capable of moral evaluation must be considered as ends in themselves (Nath, R., and Sahu, V. 2021). This gives rise to the question: can we consider artificial moral agents as ends in themselves? As argued by Weizenbaum, computer intelligence is alien to genuine human problems and concerns'. Indeed, there are several critical lacking functions artificial intelligence is unable to replicate, such as intuition, discretion, and instinct. The inability for artificial intelligence to acquire such features lead them to be incapable of moral action. Moreover, any implementation of a Kantian artificial moral agent follows procedures that ultimately reduce it to a hypothetical moral agent. (Manna, Nath 2021: 144). These systems perform actions based on their instructions, and as such can only be amoral.

Kantian ethics is an effective foundation for rationalising decisions. However, its distinct lack of human qualities required of a moral agent make it unsuitable for complete automation. Kantian proof systems in contrast may serve as effective tools for humans to formalise the morality of maxims. 

## NOT DONE
https://www.qil-qdi.org/kantian-ethics-age-artificial-intelligence-robotics/
https://www.amazon.com.au/Computer-Power-Human-Reason-Calculation/dp/0716704633
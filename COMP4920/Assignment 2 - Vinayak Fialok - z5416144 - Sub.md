### 1. Introduction
Achieving the properties of accountability, fairness and transparency is essential to acceptable Automated Decision Making (ADM), particularly for the critical life-changing ADM system of recidivism prediction. We argue that COMPAS, a recidivism prediction software, may achieve transparency through simplification of its internal reasoning without diminishing accuracy. However, COMPAS does not have sufficient accuracy to result in fairness, particularly through the effect of automation bias.

First we define that achieving accountability is to have normatively salient reasoning (fairness) and accessible, understandable reasoning (transparency). Then, we discuss how Human decision making is able to achieve fairness and transparency through the belief-desire-intention model. We define reasoning as the process/steps in coming to a decision, and explanation as the accessible and understandable communication of reasoning. We then argue that we cannot achieve transparency through the translation of reasoning to explanation, and that reasoning itself must be inherently explicable. We explore ways of explanation, determining the deductive nomological and causal explanation are sufficient to explain decision. Next, we explore how rule-lists are explicable through deductive nomological and causal explanation. We show that COMPAS can be become transparent through simplification to rule-lists without losing accuracy. Next we argue that accuracy is not sufficient to prove moral salience, but rather the reasons underlying the decision should themselves be morally salient. We discuss how rule-lists may be shown to be morally-salient through Kantian ethics. Finally, we argue that the degree to which COMPAS is accurate, even with transparency, is not sufficient for fairness through considering ADM guidelines and cognitive bias.
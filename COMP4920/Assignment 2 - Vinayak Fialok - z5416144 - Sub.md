> [!info] Question
> How might fairness, accountability, and transparency be achieved collectively by an automated decision - that is - by a decision outputted by an AI? In your answer, compare and contrast a causal account of explanation with at least one other account of explanation. Make explicit reference to the reading (and references therein) for Thursday of Week 4.
### 1. Introduction
Achieving the properties of accountability, fairness and transparency is essential to acceptable Automated Decision Making (ADM). We discuss how fairness and transparency may be jointly achieved for COMPAS, a recidivism prediction software. We argue that COMPAS may achieve transparency through simplification of its internal reasoning without diminishing accuracy. However, COMPAS does not have sufficient accuracy to result in fairness, particularly through the effect of automation bias.

First we define that achieving accountability is to have normatively salient reasoning (fairness) and accessible, understandable reasoning (transparency). Then, we discuss how Human decision making is able to achieve fairness and transparency through the belief-desire-intention model. We define reasoning as the process/steps in coming to a decision, and explanation as the accessible and understandable communication of reasoning. We then argue that we cannot achieve transparency through the translation of reasoning to explanation, and that reasoning itself must be inherently explicable. We explore ways of explanation, determining the deductive nomological and causal explanation are sufficient to explain decision. Next, we explore how rule-lists are explicable through deductive nomological and causal explanation. We show that COMPAS can be become transparent through simplification to rule-lists without losing accuracy. Next we argue that accuracy is not sufficient to prove moral salience, but rather the reasons underlying the decision should themselves be morally salient. We discuss how rule-lists may be shown to be morally-salient through Kantian ethics. Finally, we argue that the degree to which COMPAS is accurate, even with transparency, is not sufficient for fairness through considering ADM guidelines and cognitive bias.

## 2.1. Accountability, Fairness, and Transparency
First, let's define accountability, fairness and transparency. Borrowing from Grayson, we identify that **accountability requires reasons**. That is, an accountable decision is one that is reasonable. Reasonableness is a function of normatively rational salience (Grayson 2024 p5). For a reason to be normatively salient, a reason must be considered grounded in norms or morally "right" or "fair" within a given context. **So we derive our property of fairness as possessing reasons that are considered morally salient**. A decisions reasonableness also requires reportability, that is the reasons for a decision must also be understandable and accessible to its stakeholders. **So we have our last derived property of transparency which refers to the reportability of our decision.** Lets finally define that a decision that collectively achieves fairness, accountability and transparency is acceptable.

~~The question of *How might fairness, accountability, and transparency be achieved collectively by an automated decision* may then be phrased as "**How might an automated decision have reasons that are ethical in a transparent manner?**". To understand the notion of reasoning, lets explore how Grayson argues human decisions are reasonable and transparent.~~

### 2.2. Human Decision Making
**Through the belief-desire-intention model and causal explanation, humans are capable of making decisions that are fair and transparent, and as such accountable and acceptable.** Grayson explore human decision making through the a model mirroring the belief-desire-intention (BDI) agent model developed by Michael Bratman. Beliefs are the set of true statements understood by some agent, let's say Bob, such as "there is coffee in the fridge". Desires are an agent's goals, preferences and values, such as "Bob feels groggy and tired". Beliefs and desires are independent of each other. An intention is a plan, scheme or strategy formed in pursuit of an agent's desires, and based upon an agent's beliefs. The coexistence of the aforementioned belief and desire, and the lack of opposing desires such as "Bob wants to stay in bed", would culminate in the intention of "Bob will go to the kitchen and drink coffee". This line of reasoning naturally aligns itself with causal reasoning which may be phrased as "if Bob had not believed coffee lie in the fridge and Bob did not feel tired, then Bob would not have gone to get coffee". By explaining a decision using causal explanation in relation to beliefs and. By explaining a decision through beliefs and desires, a human can be transparent about a decision. Given that said beliefs and desires are normatively salient, a human can be fair.
